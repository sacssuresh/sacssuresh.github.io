<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Suresh Kumar Balasubramanian</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>

<div class="container">

    <!-- REAL SIDEBAR -->
    <aside class="sidebar">

        <div class="photo-card">
            <img src="assets/profile.jpg" class="sidebar-photo" alt="Suresh">
        </div>

        <h2 class="sidebar-name">Suresh Kumar<br>Balasubramanian</h2>
        <p class="sidebar-title">How do I think when no one is interviewing me?</p>

        <div class="sidebar-content">
            <h3>About Me</h3>
            <p>
                I like building things that are simple, reliable, and meaningful.
                I enjoy breaking down complex ideas and understanding how systems behave.
            </p>

            <h3>Navigation</h3>
            <p><a href="index.html">Home</a></p>
            <p><a href="interests.html">Interests</a></p>

            <div class="sidebar-divider"></div>

            <h3>Links</h3>
            <p><a href="https://github.com/sacssuresh" target="_blank">GitHub</a></p>
            <p><a href="https://www.linkedin.com/in/sureshkumar-bala/" target="_blank">LinkedIn</a></p>
            <p><a href="mailto:suresh@example.com">Email</a></p>
        </div>

    </aside>
    <!-- END SIDEBAR -->


    <!-- MAIN CONTENT -->
    <main class="content">

        <h1>Professional work and what I do for a living</h1>
        <p class="intro-text">
            I enjoy building systems that feel simple, reliable, and thoughtful.
            Most of my work revolves around understanding real-world behavior
            and designing solutions that stay practical and predictable.
        </p>

        <h2>Work</h2>

<section id="Tapsy" class="feed-item">
    <h3>Tapsy Mobile App</h3>

    <p>
        Tapsy began as a thought experiment to understand how quickly a modern mobile app
        can be built and released using today’s tooling.
        The intention was not to create a feature-rich product, but to observe
        the full journey from idea to production under realistic constraints.
    </p>

    <p>
        The core application was built in roughly three hours using React Native,
        with Cursor and ChatGPT assisting in scaffolding and iteration.
        Writing the code itself was surprisingly straightforward —
        modern frameworks and AI tools have made shipping functionality faster than ever.
    </p>

    <p>
        What turned out to be significantly harder were the things around the code.
        App store compliance, Expo configuration, signing, environment setup,
        and platform-specific checks consumed far more time than development itself.
        This gap between “working code” and “production-ready software” was very noticeable.
    </p>

    <p>
        Beyond release mechanics, the real complexity surfaced in non-functional concerns:
        observability, security, secrets management, and defining sensible reliability boundaries.
        These aspects are rarely visible in demos, but they ultimately determine
        whether a system is safe, operable, and sustainable.
    </p>

    <p>
        The experiment reinforced a lesson I’ve seen repeatedly in larger systems as well:
        shipping features is increasingly easy,
        but building software that can be trusted, observed, and operated in the real world
        is where most of the engineering effort still lives.
    </p>

    <p>
        The source code for this experiment is available on GitHub:
        <a href="https://github.com/sacssuresh/Tapsy" target="_blank" rel="noopener">
            github.com/sacssuresh/Tapsy
        </a>
    </p>
</section>


        <h2>Writing</h2>

      <section id="Observability" class="feed-item">
    <h3>Observability vs Monitoring</h3>

    <p>
        Monitoring tells you <em>what</em> is happening.  
        Observability helps you understand <em>why</em> it’s happening.
    </p>

    <p>
        Monitoring is tool-driven — dashboards, alerts, metrics.  
        Observability is behaviour-driven — signals, traces, and context that reveal how a system behaves under real-world conditions.
    </p>

    <h4>How do you set up effective monitoring?</h4>

    <p>
        In my experience, the foundation of monitoring must be driven by a senior architect or a distinguished engineer — not delegated downward. 
        Proper monitoring is a first-class architecture concern.
    </p>

    <p><strong>Step 1 — Define SLAs, SLOs, and Error Budgets</strong><br>
       Sit down and write your service-level objectives clearly.  
       Define acceptable latency, slowness, and failure windows.  
       These numbers drive everything else.
    </p>

    <p>
        <em>Example:</em>  
        A user-facing authentication service needs tighter alert boundaries than a notification service.  
        A missed login breaks the user journey; a delayed notification does not.
    </p>

    <p><strong>Step 2 — Socialize shared language</strong><br>
       Teams should deeply understand terms like <em>error budget</em>, <em>acceptable downtime</em>, and <em>recovery time</em>.  
       Without common language, monitoring becomes inconsistent across services.
    </p>

    <p><strong>Step 3 — Prefer percentages, not raw counts</strong><br>
       “Error rate > 5%” is correct.  
       “Error count > 10” is not.  
       Percentages scale with traffic; raw counts don’t.
    </p>

    <p><strong>Step 4 — Avoid unnecessary alerts</strong><br>
       Alert fatigue is very real.  
       I’ve seen on-call engineers and escalation leads get woken up at midnight for alerts that were simply misconfigured.
    </p>

    <p>
        <em>Example:</em>  
        Firing an alert for “error increase in last 15 minutes” is misleading.  
        What you want is a <strong>sustained</strong> error rate increase, not small pockets of failure due to natural downstream variance, throttling, or partner system hiccups.
    </p>

    <h4>Modern Tooling</h4>

    <p>
        Modern observability platforms offer anomaly detection, pattern-based alerting, and AI-assisted insights.  
        But the real value still comes from choosing an architecture that fits your system’s nature, scale, and cost boundaries.
    </p>

    <h4>What I Prefer</h4>

    <p>
        I like OpenTelemetry for tracing, Prometheus for metrics, and Elastic for logs.  
        It’s a modern, clean, vendor-neutral setup — but cost remains the invisible architecture decision-maker.
    </p>

    <p>
        Over the years, I’ve also used AppDynamics, Datadog, and Splunk. All are excellent tools if cost is not your top concern.
    </p>
</section>


        <section id="Scalable" class="feed-item">
            <h3>Designing Scalable IoT Platforms</h3>
            <p>Notes on handling real-world scale and behavior.</p>
        </section>

        <section id="Event-Driven" class="feed-item">
            <h3>Event-Driven Architecture</h3>
            <p>Why predictable asynchronous flows matter.</p>
        </section>

    </main>
    <nav class="right-column">
    <h4>On this page</h4>
    <a href="#Tapsy">Tapsy</a>
    <a href="#Observability">Observability vs Monitoring</a>
    <a href="#Scalable">Designing Scalable IoT Platforms</a>
    <a href="#Event-Driven">Event-Driven Architecture</a>
</nav>

</div>

</body>
</html>


